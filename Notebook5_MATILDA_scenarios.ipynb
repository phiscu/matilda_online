{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90e24a2-d414-478d-81ad-4a69baf541d0",
   "metadata": {},
   "source": [
    "# MATILDA Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e3d49-e95d-435d-abe6-36de29ac20f6",
   "metadata": {},
   "source": [
    "After calibrating MATILDA we can now use the best parameter set to run the model with climate scenario data until 2100. In this notebook we will...\n",
    "\n",
    "- ...run MATILDA with the same parameters and settings for two emission scenarios and all models of the ensemble.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> On a single CPU one MATILDA run over 120y takes ~4s. For all ensemble members this adds up to ~4min. The <code>MatildaBulkProcessor</code> class allows you to reduce this time significantly with more CPUs so you might want to run this notebook locally. Or have a coffee. Again...</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02dcda-b1a9-4e1b-b172-f0ab8e16f415",
   "metadata": {},
   "source": [
    "## Set up the scenario runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434caf4-d9da-4ae5-903e-d7facdd9e6c6",
   "metadata": {},
   "source": [
    "As before, we start by reading our paths from the `config.ini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582b6ee5-693a-401b-ac7b-1f69b04d739a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input path: 'input/'\n",
      "Output path: 'output/'\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "# read local config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "# get directories from config.ini\n",
    "dir_input = config['FILE_SETTINGS']['DIR_INPUT']\n",
    "dir_output = config['FILE_SETTINGS']['DIR_OUTPUT']\n",
    "zip_output = config['CONFIG']['ZIP_OUTPUT']\n",
    "\n",
    "# set the file format for storage\n",
    "compact_files = config.getboolean('CONFIG','COMPACT_FILES')\n",
    "\n",
    "# get the number of available cores\n",
    "num_cores = int(config['CONFIG']['NUM_CORES'])\n",
    "\n",
    "print(f\"Input path: '{dir_input}'\")\n",
    "print(f\"Output path: '{dir_output}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02e4aa6-a290-4801-b3ac-318285c7822e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Choose in the config between faster <code>pickle</code> files and smaller <code>parquet</code> files.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcceea2-b3a9-46d5-a403-b274269d40ed",
   "metadata": {},
   "source": [
    "Let's extend the modeling period to the full century. Therefore, we read the `settings.yaml` to a ditionary and change the respective settings. We also turn off the plotting module to reduce processing time and add the glacier profile from its `.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe56f39-49b5-4c59-8a8d-662efd110483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings for MATILDA scenario runs:\n",
      "\n",
      "area_cat: 300.6637184185051\n",
      "area_glac: 31.829413146586116\n",
      "ele_cat: 3271.895648388366\n",
      "ele_dat: 3324.5555520312164\n",
      "ele_glac: 4001.8798828125\n",
      "elev_rescaling: True\n",
      "freq: M\n",
      "lat: 42.18511742495568\n",
      "plot_type: all\n",
      "set_up_end: 1999-12-31\n",
      "set_up_start: 1998-01-01\n",
      "sim_end: 2100-12-31\n",
      "sim_start: 2000-01-01\n",
      "warn: False\n",
      "glacier_profile:      Elevation      Area          WE  EleZone\n",
      "0         1970  0.000000      0.0000     1900\n",
      "1         2000  0.000000      0.0000     2000\n",
      "2         2100  0.000000      0.0000     2100\n",
      "3         2200  0.000000      0.0000     2200\n",
      "4         2300  0.000000      0.0000     2300\n",
      "..         ...       ...         ...      ...\n",
      "156       4730  0.000023  20721.3700     4700\n",
      "157       4740  0.000012  14450.2180     4700\n",
      "158       4750  0.000006  10551.4730     4700\n",
      "159       4760  0.000000      0.0000     4700\n",
      "160       4780  0.000002   6084.7456     4700\n",
      "\n",
      "[161 rows x 4 columns]\n",
      "plots: False\n"
     ]
    }
   ],
   "source": [
    "from tools.helpers import read_yaml, write_yaml\n",
    "import pandas as pd\n",
    "matilda_settings = read_yaml(f\"{dir_output}/settings.yml\")\n",
    "adapted_settings = {\n",
    "    \"set_up_start\": '1998-01-01',  # Start date of the setup period\n",
    "    \"set_up_end\": '1999-12-31',  # End date of the setup period\n",
    "    \"sim_start\": '2000-01-01',  # Start date of the simulation period\n",
    "    \"sim_end\": '2100-12-31',  # End date of the simulation period\n",
    "    \"plots\": False\n",
    "}\n",
    "matilda_settings['glacier_profile'] = pd.read_csv(f\"{dir_output}/glacier_profile.csv\")\n",
    "\n",
    "matilda_settings.update(adapted_settings)\n",
    "\n",
    "print(\"Settings for MATILDA scenario runs:\\n\")\n",
    "for key in matilda_settings.keys(): print(key + ': ' + str(matilda_settings[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca1800-4f02-4a4f-9784-e050a4bb2487",
   "metadata": {},
   "source": [
    "Now, we read the calibrated parameter set from the `parameters.yml` and our forcing data from the binary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b272ac4-724c-401b-8ace-86a31b94aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters loaded.\n",
      "Forcing data loaded.\n"
     ]
    }
   ],
   "source": [
    "from tools.helpers import parquet_to_dict, pickle_to_dict\n",
    "\n",
    "param_dict = read_yaml(f\"{dir_output}/parameters.yml\")\n",
    "print(\"Parameters loaded.\")\n",
    "\n",
    "if compact_files:\n",
    "    # For size:\n",
    "    tas = parquet_to_dict(f\"{dir_output}cmip6/adjusted/tas_parquet\")\n",
    "    pr = parquet_to_dict(f\"{dir_output}cmip6/adjusted/pr_parquet\")\n",
    "else:\n",
    "    # For speed\n",
    "    tas = pickle_to_dict(f\"{dir_output}cmip6/adjusted/tas.pickle\")\n",
    "    pr = pickle_to_dict(f\"{dir_output}cmip6/adjusted/pr.pickle\")\n",
    "\n",
    "print(\"Forcing data loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1297ba3-5245-4eb9-b9ca-175cf40f89fc",
   "metadata": {},
   "source": [
    "The `create_scenario_dict` function converts the individual climate projections into MATILDA input dataframes. We store the ensemble of MATILDA inputs in a nested dictionary again and save the file in a `parquet` (or `pickle`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6967a309-7dec-4b81-971c-aacb0d541e40",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing MATILDA scenario input dataframes on disk...\n"
     ]
    }
   ],
   "source": [
    "from tools.helpers import dict_to_parquet, dict_to_pickle, create_scenario_dict\n",
    "\n",
    "scenarios = create_scenario_dict(tas, pr, [2, 5])\n",
    "\n",
    "print(\"Storing MATILDA scenario input dataframes on disk...\")\n",
    "\n",
    "if compact_files:\n",
    "    dict_to_parquet(scenarios, f\"{dir_output}cmip6/adjusted/matilda_scenario_input_parquet\")\n",
    "else:\n",
    "    dict_to_pickle(scenarios, f\"{dir_output}cmip6/adjusted/matilda_scenario_input.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ce469-675b-4612-8f82-bf177243c366",
   "metadata": {},
   "source": [
    "## Running MATILDA for all climate projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93b379-d00f-437f-933f-1c602bc61534",
   "metadata": {},
   "source": [
    "Now that we are set up we need to **run MATILDA for every CMIP6 model and both scenarios**. This adds up to **50-70 model runs at ~4s each** on a single core, depending on how many models remained in your ensemble. So you can either start the bulk processor and have a break or download the repo and change the config according to your available cores.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Don't be confused by the status bar. It only updates after one full scenario is processed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f082b4d-db3d-437f-9be7-b141d13d4aba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute '__spec__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m     matilda_scenarios = matilda_bulk.run_single_process()\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     matilda_scenarios = \u001b[43mmatilda_bulk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_multi_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_cores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_cores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStoring MATILDA scenario outputs on disk...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compact_files:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Klima_HU/matilda/matilda_online/tools/helpers.py:727\u001b[39m, in \u001b[36mMatildaBulkProcessor.run_multi_process\u001b[39m\u001b[34m(self, num_cores)\u001b[39m\n\u001b[32m    717\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    718\u001b[39m \u001b[33;03mRuns the MATILDA simulations for the scenarios and models in multi-processing mode and returns a dictionary\u001b[39;00m\n\u001b[32m    719\u001b[39m \u001b[33;03mof results.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    723\u001b[39m \u001b[33;03m    A dictionary of MATILDA simulation results.\u001b[39;00m\n\u001b[32m    724\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    726\u001b[39m out_dict = {}  \u001b[38;5;66;03m# Create an empty dictionary to store the outputs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_cores\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    728\u001b[39m     \u001b[38;5;66;03m# Loop over the scenarios with progress bar\u001b[39;00m\n\u001b[32m    729\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m scenario \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m.scenarios.keys(), desc=\u001b[33m\"\u001b[39m\u001b[33mScenarios SSP2 and SSP5\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    730\u001b[39m         model_dict = {}  \u001b[38;5;66;03m# Create an empty dictionary to store the model outputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/context.py:119\u001b[39m, in \u001b[36mBaseContext.Pool\u001b[39m\u001b[34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''Returns a process pool object'''\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpool\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/pool.py:215\u001b[39m, in \u001b[36mPool.__init__\u001b[39m\u001b[34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28mself\u001b[39m._processes = processes\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_repopulate_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/pool.py:306\u001b[39m, in \u001b[36mPool._repopulate_pool\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repopulate_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_repopulate_pool_static\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inqueue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_outqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrap_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/pool.py:329\u001b[39m, in \u001b[36mPool._repopulate_pool_static\u001b[39m\u001b[34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[39m\n\u001b[32m    327\u001b[39m w.name = w.name.replace(\u001b[33m'\u001b[39m\u001b[33mProcess\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mPoolWorker\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    328\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m pool.append(w)\n\u001b[32m    331\u001b[39m util.debug(\u001b[33m'\u001b[39m\u001b[33madded worker\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/context.py:288\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/popen_spawn_posix.py:42\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     40\u001b[39m tracker_fd = resource_tracker.getfd()\n\u001b[32m     41\u001b[39m \u001b[38;5;28mself\u001b[39m._fds.append(tracker_fd)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m prep_data = \u001b[43mspawn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_preparation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m fp = io.BytesIO()\n\u001b[32m     44\u001b[39m set_spawning_popen(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/matilda_edu/lib/python3.11/multiprocessing/spawn.py:187\u001b[39m, in \u001b[36mget_preparation_data\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Figure out whether to initialise main in the subprocess as a module\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;66;03m# or through direct execution (or to leave it alone entirely)\u001b[39;00m\n\u001b[32m    186\u001b[39m main_module = sys.modules[\u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m main_mod_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mmain_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__spec__\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m main_mod_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m     d[\u001b[33m'\u001b[39m\u001b[33minit_main_from_name\u001b[39m\u001b[33m'\u001b[39m] = main_mod_name\n",
      "\u001b[31mAttributeError\u001b[39m: module '__main__' has no attribute '__spec__'"
     ]
    }
   ],
   "source": [
    "from tools.helpers import MatildaBulkProcessor\n",
    "import shutil\n",
    "\n",
    "# Create an instance of the MatildaBulkProcessor class\n",
    "matilda_bulk = MatildaBulkProcessor(scenarios, matilda_settings, param_dict)\n",
    "\n",
    "# Run Matilda in a loop (takes a while - have a coffee)\n",
    "if num_cores == 1:\n",
    "    matilda_scenarios = matilda_bulk.run_single_process()\n",
    "else:\n",
    "    matilda_scenarios = matilda_bulk.run_multi_process(num_cores=num_cores)\n",
    "\n",
    "print(\"Storing MATILDA scenario outputs on disk...\")\n",
    "\n",
    "if compact_files:\n",
    "    dict_to_parquet(matilda_scenarios, f\"{dir_output}cmip6/adjusted/matilda_scenarios_parquet\")\n",
    "else:\n",
    "    dict_to_pickle(matilda_scenarios, f\"{dir_output}cmip6/adjusted/matilda_scenarios.pickle\")\n",
    "\n",
    "if zip_output:\n",
    "    # refresh `output_download.zip` with data retrieved within this notebook\n",
    "    shutil.make_archive('output_download', 'zip', 'output')\n",
    "    print('Output folder can be download now (file output_download.zip)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f932e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a8537b-58ea-47b9-983a-6e0971c38c9d",
   "metadata": {},
   "source": [
    "The result is a large nested dictionary with 100-140 dataframes of MATILDA outputs. Now, it is finally time to look at the results. Explore your projections in [Notebook 6](Notebook6_Analysis.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matilda_edu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
